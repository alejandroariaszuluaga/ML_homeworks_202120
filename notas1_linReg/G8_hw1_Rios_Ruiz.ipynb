{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ML_hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Y5SGXkG3Ja"
      },
      "source": [
        "\n",
        "| Universidad de los Andes<br>Departamento de Ingeniería Eléctrica y Electrónica<br>Machine Learning<br>Ríos Beltrán Manuel Sebastián - Código 201317670<br>Ruiz Ruiz Alison Gissell - Código 202116230<br><br><p style=\"font-size:30px\">Taller 1 - Regresión Lineal: Predicción de Precios de Autos </p> \t||\n",
        "|-----------------------------------------------------------------------------------\t|---\t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSCQlICMD8Cd"
      },
      "source": [
        "Una tarea bastante común en el contexto de Machine Learning es la predicción de una variable según algunos descriptores. En esta ocasión partiremos de un dataset que involucra ocho variables (algunas numéricas, otras categóricas) y el precio de un automóvil, el cual se desea estimar empleando un modelo de regresión lineal.\n",
        "\n",
        "**Objetivos:**\n",
        "- Aprender a lidiar con descriptores categóricos no-numéricos.\n",
        "- Usar la librería Pandas para manejar datos tabulares en formato .csv.\n",
        "- Emplear la librería Scikit Learn para preprocesamiento y entrenamiento de un modelo de regresión lineal.\n",
        "- Implementar el algoritmo Descenso de Gradiente Estocástico para un modelo lineal básico.\n",
        "\n",
        "Inicialmente se importan las librerías necesarias para llevar a cabo el manejo de los datos y los entrenamientos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6EBVybVD8Ch",
        "outputId": "d86debd2-fdf9-41a1-ba18-f4f16c785e22"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADfCfc_HWsO9"
      },
      "source": [
        "Se importa el archivo con el dataset que se emplea para los entrenamiento y se observa la estructura de este archivo, donde se tienen variables no númericas (modelo, tipo de transmisión y de combustible) y númericas (año, kilometraje, entre otros), donde el target de los modelos a construir consiste en predecir el valor del precio, basado en las demás características, por ende la etiqueta de salida de entrenamiento corresponde a esta etiqueta que se encuentra en la columna 3: price. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "47qm4dSMD8Ci",
        "outputId": "934b189d-7dbb-4c25-83a3-f0bcc5cc138d"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ML/HW1/carDataset/toyota.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GT86</td>\n",
              "      <td>2016</td>\n",
              "      <td>16000</td>\n",
              "      <td>Manual</td>\n",
              "      <td>24089</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>265</td>\n",
              "      <td>36.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GT86</td>\n",
              "      <td>2017</td>\n",
              "      <td>15995</td>\n",
              "      <td>Manual</td>\n",
              "      <td>18615</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145</td>\n",
              "      <td>36.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GT86</td>\n",
              "      <td>2015</td>\n",
              "      <td>13998</td>\n",
              "      <td>Manual</td>\n",
              "      <td>27469</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>265</td>\n",
              "      <td>36.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GT86</td>\n",
              "      <td>2017</td>\n",
              "      <td>18998</td>\n",
              "      <td>Manual</td>\n",
              "      <td>14736</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150</td>\n",
              "      <td>36.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GT86</td>\n",
              "      <td>2017</td>\n",
              "      <td>17498</td>\n",
              "      <td>Manual</td>\n",
              "      <td>36284</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145</td>\n",
              "      <td>36.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
              "0   GT86  2016  16000       Manual    24089   Petrol  265  36.2         2.0\n",
              "1   GT86  2017  15995       Manual    18615   Petrol  145  36.2         2.0\n",
              "2   GT86  2015  13998       Manual    27469   Petrol  265  36.2         2.0\n",
              "3   GT86  2017  18998       Manual    14736   Petrol  150  36.2         2.0\n",
              "4   GT86  2017  17498       Manual    36284   Petrol  145  36.2         2.0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ujsHflEYjww"
      },
      "source": [
        "Para obtener la información del dataset a nivel general, se emplea el comando *df.info()*, donde se conoce que el dataset consta de 6738 filas de datos con las nueve columnas correspondientes a cada variable visualizada en la celda anterior. El dataset posee 3 variables categoricas y 6 numéricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pzRgnvD8Cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7064dd05-e6fb-4b0c-dac4-54a26c54d270"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6738 entries, 0 to 6737\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   model         6738 non-null   object \n",
            " 1   year          6738 non-null   int64  \n",
            " 2   price         6738 non-null   int64  \n",
            " 3   transmission  6738 non-null   object \n",
            " 4   mileage       6738 non-null   int64  \n",
            " 5   fuelType      6738 non-null   object \n",
            " 6   tax           6738 non-null   int64  \n",
            " 7   mpg           6738 non-null   float64\n",
            " 8   engineSize    6738 non-null   float64\n",
            "dtypes: float64(2), int64(4), object(3)\n",
            "memory usage: 473.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbTMKvV3D8Cj"
      },
      "source": [
        "Podemos observar algunas categorías numéricas, y otras de tipo _object_ (string)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cbeO5p3D8Cj"
      },
      "source": [
        "categ = ['model','year','transmission','fuelType','engineSize']\n",
        "str_categ = ['model','transmission','fuelType']\n",
        "numer = ['price','mileage','tax','mpg']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVS5d6eRD8Ck"
      },
      "source": [
        "## Parte 1\n",
        "\n",
        "A continuación se realiza el ajuste de los datos para un modelo de regresión lineal definido mediante la librería SciKit-Learn. Se observan dos métricas de precisión, en este caso Error Cuadrático Medio (RMSE) y $R^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U6Nw6P7D8Ck"
      },
      "source": [
        "#### Casos:\n",
        "\n",
        "- Caso 1: Codificación One-Hot (MinMaxScaler)\n",
        "- Caso 2: Codificación Ordinal (MinMaxScaler)\n",
        "- Caso 3: Codificación One-Hot (RobustScaler)\n",
        "- Caso 4: Codificación Ordinal (RobustScaler)\n",
        "- Caso 5: Entrenar con un 30% (Codificación Ordinal, MinMaxScaler)\n",
        "- Caso 6: Entrenar con un 55% (Codificación Ordinal, MinMaxScaler)\n",
        "- Caso 7: Entrenar con un 80% (Codificación Ordinal, MinMaxScaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLEQte2RD8Cl"
      },
      "source": [
        "### Caso 1:\n",
        "#### Codificación One-Hot  (MinMaxScaler)\n",
        "\n",
        "Una de las formas de codificar categorías no numéricas se conoce como _One-Hot encoding_, en donde se crea una columna para cada valor distinto que exista en la característica que estamos codificando y, para cada registro, marcar con un 1 la columna a la que pertenezca dicho registro y dejar las demás con 0, convirtiendo una variable categórica en varias variables. Como se observa a continuación, la variable de transmisión se dividió en automática, manual u otra, de la misma manera funciona con las otras dos variables categóricas al aplicar el One-Hot, pasando de tener 9 variables a muchas más, de acuerdo con la cantidad de categorías de cada una.\n",
        "\n",
        "En este caso se realiza un escalamiento de los datos utilizando un *MinMaxScaler*, el cual resta el valor mínimo de la característica y luego divide por el rango (donde el rango es la diferencia entre el máximo y el mínimo), normalizando los datos para que queden entre 0 y 1 sin modificar la distribución original de los datos, como se evidencia a continuación, efectivamente quedan los rangos de los valores entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RAXGQ_NED8Cm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "790d25a6-d8c3-4efe-dcb6-357d394955b2"
      },
      "source": [
        "df_ohe = pd.get_dummies(df)\n",
        "scaler = MinMaxScaler()\n",
        "df_scl_ohe = scaler.fit_transform(df_ohe)\n",
        "df_scl_ohe = pd.DataFrame(df_scl_ohe, columns = df_ohe.columns)\n",
        "df_scl_ohe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>mileage</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "      <th>model_ Auris</th>\n",
              "      <th>model_ Avensis</th>\n",
              "      <th>model_ Aygo</th>\n",
              "      <th>model_ C-HR</th>\n",
              "      <th>model_ Camry</th>\n",
              "      <th>model_ Corolla</th>\n",
              "      <th>model_ GT86</th>\n",
              "      <th>model_ Hilux</th>\n",
              "      <th>model_ IQ</th>\n",
              "      <th>model_ Land Cruiser</th>\n",
              "      <th>model_ PROACE VERSO</th>\n",
              "      <th>model_ Prius</th>\n",
              "      <th>model_ RAV4</th>\n",
              "      <th>model_ Supra</th>\n",
              "      <th>model_ Urban Cruiser</th>\n",
              "      <th>model_ Verso</th>\n",
              "      <th>model_ Verso-S</th>\n",
              "      <th>model_ Yaris</th>\n",
              "      <th>transmission_Automatic</th>\n",
              "      <th>transmission_Manual</th>\n",
              "      <th>transmission_Other</th>\n",
              "      <th>transmission_Semi-Auto</th>\n",
              "      <th>fuelType_Diesel</th>\n",
              "      <th>fuelType_Hybrid</th>\n",
              "      <th>fuelType_Other</th>\n",
              "      <th>fuelType_Petrol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       year     price  ...  fuelType_Other  fuelType_Petrol\n",
              "0  0.818182  0.256150  ...             0.0              1.0\n",
              "1  0.863636  0.256066  ...             0.0              1.0\n",
              "2  0.772727  0.222301  ...             0.0              1.0\n",
              "3  0.863636  0.306839  ...             0.0              1.0\n",
              "4  0.863636  0.281478  ...             0.0              1.0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4I6kkS_D8Cm"
      },
      "source": [
        "#### Separación de Datos\n",
        "\n",
        "Para entrenar, se requiere separar los label target del resto de información, para ello se crea un dataframe Y con la información de precio y un dataframe X con la demás información. Adicionalmente, se requiere hacer un split de los datos en el conjunto de entrenamiento y de prueba, con el cual se mide el porcentaje de precisión y error a través de las épocas de entrenamiento, en este caso se emplea un 80% del dataset para entrenar y un 20% para test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIQ-u1tXD8Cm"
      },
      "source": [
        "X = df_scl_ohe.drop(['price'], axis=1)\n",
        "y = df_scl_ohe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzP9wHM9ZIBq"
      },
      "source": [
        "Se crea el modelo de regresión lineal de sklearn, se entrena y se calcula el Error Cuadrado $R^2$ y Error Cuadrático Medio (RMSE) para evaluar el comportamiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLNdjkCxD8Cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40d9170-e194-4a6c-ad12-808a14d50580"
      },
      "source": [
        "model_1 = LinearRegression()\n",
        "\n",
        "model_1.fit(X_train, y_train)\n",
        "preds = model_1.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_1.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.031\n",
            "R^2: 0.917\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qkNu2BYD8Cn"
      },
      "source": [
        "### Caso 2\n",
        "\n",
        "#### Codificación Ordinal  (MinMaxScaler)\n",
        "\n",
        "Otra forma de codificar categorías no numéricas se conoce como _ordinal encoding_, en donde se asigna a cada categoría un valor numérico, como se observa a continuación, las variables de modelo, tipo de transmisión y combustible poseen ahora una variable numérica que no cambia en las primeras cinco filas ya que para estas filas las categorías permanecían iguales entre sí. A diferencia del One-Hot, se mantienen las 9 columnas de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pvjqkLOD8Cn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dcb6cb89-c2ed-47ae-cf6f-ee74a06cb477"
      },
      "source": [
        "oe = OrdinalEncoder()\n",
        "df_oe = df.copy()\n",
        "df_oe[str_categ] = oe.fit_transform(df_oe[str_categ])\n",
        "\n",
        "x = df_oe.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df_scl_oe = pd.DataFrame(x_scaled, columns=df_oe.columns)\n",
        "df_scl_oe.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model      year     price  ...       tax       mpg  engineSize\n",
              "0  0.352941  0.818182  0.256150  ...  0.469027  0.143842    0.444444\n",
              "1  0.352941  0.863636  0.256066  ...  0.256637  0.143842    0.444444\n",
              "2  0.352941  0.772727  0.222301  ...  0.469027  0.143842    0.444444\n",
              "3  0.352941  0.863636  0.306839  ...  0.265487  0.143842    0.444444\n",
              "4  0.352941  0.863636  0.281478  ...  0.256637  0.143842    0.444444\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6AYQXu5D8Co"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wv0GWU22D8Co"
      },
      "source": [
        "X = df_scl_oe.drop(['price'], axis=1)\n",
        "y = df_scl_oe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7poJWBeD8Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620cd618-7174-4f95-bb9c-94bcd86bfb0d"
      },
      "source": [
        "model_2 = LinearRegression()\n",
        "\n",
        "model_2.fit(X_train, y_train)\n",
        "preds = model_2.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_2.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.05\n",
            "R^2: 0.787\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDl-UJaMD8Cp"
      },
      "source": [
        "### Caso 3\n",
        "\n",
        "#### Codificación One-Hot (RobustScaler)\n",
        "\n",
        "En este caso se emplea el escalamiento de datos RobustScaler, que transforma el vector de datos restando la mediana y dividiendo por el rango intercuartíloco (valor del 75% - valor del 25%), como los datos en este caso obtienen una transformación, ésta reduce importancia a outlayers si estos existen en los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcHwKtD-D8Cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "f37aa8d9-cb02-44e5-bc7f-43f485231d5f"
      },
      "source": [
        "df_ohe = pd.get_dummies(df)\n",
        "scaler = RobustScaler()\n",
        "df_rscl_ohe = scaler.fit_transform(df_ohe)\n",
        "df_rscl_ohe = pd.DataFrame(df_scl_ohe, columns = df_ohe.columns)\n",
        "df_rscl_ohe.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>mileage</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "      <th>model_ Auris</th>\n",
              "      <th>model_ Avensis</th>\n",
              "      <th>model_ Aygo</th>\n",
              "      <th>model_ C-HR</th>\n",
              "      <th>model_ Camry</th>\n",
              "      <th>model_ Corolla</th>\n",
              "      <th>model_ GT86</th>\n",
              "      <th>model_ Hilux</th>\n",
              "      <th>model_ IQ</th>\n",
              "      <th>model_ Land Cruiser</th>\n",
              "      <th>model_ PROACE VERSO</th>\n",
              "      <th>model_ Prius</th>\n",
              "      <th>model_ RAV4</th>\n",
              "      <th>model_ Supra</th>\n",
              "      <th>model_ Urban Cruiser</th>\n",
              "      <th>model_ Verso</th>\n",
              "      <th>model_ Verso-S</th>\n",
              "      <th>model_ Yaris</th>\n",
              "      <th>transmission_Automatic</th>\n",
              "      <th>transmission_Manual</th>\n",
              "      <th>transmission_Other</th>\n",
              "      <th>transmission_Semi-Auto</th>\n",
              "      <th>fuelType_Diesel</th>\n",
              "      <th>fuelType_Hybrid</th>\n",
              "      <th>fuelType_Other</th>\n",
              "      <th>fuelType_Petrol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       year     price  ...  fuelType_Other  fuelType_Petrol\n",
              "0  0.818182  0.256150  ...             0.0              1.0\n",
              "1  0.863636  0.256066  ...             0.0              1.0\n",
              "2  0.772727  0.222301  ...             0.0              1.0\n",
              "3  0.863636  0.306839  ...             0.0              1.0\n",
              "4  0.863636  0.281478  ...             0.0              1.0\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcVL57uyD8Cq"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ojz3hCbuD8Cq"
      },
      "source": [
        "X = df_rscl_ohe.drop(['price'], axis=1)\n",
        "y = df_rscl_ohe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXW3ZMG9D8Cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3f2471-b3e1-4f68-a69a-50f52072da00"
      },
      "source": [
        "model_3 = LinearRegression()\n",
        "\n",
        "model_3.fit(X_train, y_train)\n",
        "preds = model_3.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_3.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.031\n",
            "R^2: 0.917\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP_axn1tD8Cr"
      },
      "source": [
        "### Caso 4\n",
        "\n",
        "#### Codificación Ordinal (RobustScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZavDxSCD8Cr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d9359c3c-7c55-421d-9370-5f0ce785d0c8"
      },
      "source": [
        "oe = OrdinalEncoder()\n",
        "df_oe = df.copy()\n",
        "df_oe[str_categ] = oe.fit_transform(df_oe[str_categ])\n",
        "\n",
        "x = df_oe.values #returns a numpy array\n",
        "robust_scaler = RobustScaler()\n",
        "x_scaled = robust_scaler.fit_transform(x)\n",
        "df_scl_oe = pd.DataFrame(x_scaled, columns=df_oe.columns)\n",
        "df_scl_oe.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.776286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257936</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>-1.955882</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.775541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>-1.955882</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.477703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>-1.955882</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.223415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.174718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>-1.955882</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.999702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.822056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>-1.955882</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model  year     price  ...       tax       mpg  engineSize\n",
              "0  0.066667  -0.5  0.776286  ...  0.896552 -1.955882       0.625\n",
              "1  0.066667   0.0  0.775541  ...  0.068966 -1.955882       0.625\n",
              "2  0.066667  -1.0  0.477703  ...  0.896552 -1.955882       0.625\n",
              "3  0.066667   0.0  1.223415  ...  0.103448 -1.955882       0.625\n",
              "4  0.066667   0.0  0.999702  ...  0.068966 -1.955882       0.625\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAwtr732D8Cr"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1_HX-aGpD8Cr"
      },
      "source": [
        "X = df_scl_oe.drop(['price'], axis=1)\n",
        "y = df_scl_oe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SdgEypED8Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806d987e-de50-4906-e948-9b87b5104026"
      },
      "source": [
        "model_4 = LinearRegression()\n",
        "\n",
        "model_4.fit(X_train, y_train)\n",
        "preds = model_4.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_4.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.444\n",
            "R^2: 0.787\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfuKW_SxD8Cs"
      },
      "source": [
        "### Caso 5\n",
        "\n",
        "#### Caso 5: Entrenar con un 30% (Codificación Ordinal, MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOWwgOzyD8Cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "374298d8-0bf7-4842-ad19-d0256d8669d5"
      },
      "source": [
        "oe = OrdinalEncoder()\n",
        "df_oe = df.copy()\n",
        "df_oe[str_categ] = oe.fit_transform(df_oe[str_categ])\n",
        "\n",
        "x = df_oe.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df_scl_oe = pd.DataFrame(x_scaled, columns=df_oe.columns)\n",
        "df_scl_oe.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model      year     price  ...       tax       mpg  engineSize\n",
              "0  0.352941  0.818182  0.256150  ...  0.469027  0.143842    0.444444\n",
              "1  0.352941  0.863636  0.256066  ...  0.256637  0.143842    0.444444\n",
              "2  0.352941  0.772727  0.222301  ...  0.469027  0.143842    0.444444\n",
              "3  0.352941  0.863636  0.306839  ...  0.265487  0.143842    0.444444\n",
              "4  0.352941  0.863636  0.281478  ...  0.256637  0.143842    0.444444\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBC20rSAD8Ct"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "No9gTLFyD8Ct"
      },
      "source": [
        "X = df_scl_oe.drop(['price'], axis=1)\n",
        "y = df_scl_oe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=22)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMEjz3iYD8Ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390f7df2-9ea0-46ba-dc50-5e2e7ad7cefb"
      },
      "source": [
        "model_5 = LinearRegression()\n",
        "\n",
        "model_5.fit(X_train, y_train)\n",
        "preds = model_5.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_5.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.049\n",
            "R^2: 0.785\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_oSLU1GD8Ct"
      },
      "source": [
        "### Caso 6\n",
        "\n",
        "#### Caso 5: Entrenar con un 55% (Codificación Ordinal, MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9JryTs9D8Ct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "04ed43f7-b538-4292-9037-ff54e6159829"
      },
      "source": [
        "oe = OrdinalEncoder()\n",
        "df_oe = df.copy()\n",
        "df_oe[str_categ] = oe.fit_transform(df_oe[str_categ])\n",
        "\n",
        "x = df_oe.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df_scl_oe = pd.DataFrame(x_scaled, columns=df_oe.columns)\n",
        "df_scl_oe.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model      year     price  ...       tax       mpg  engineSize\n",
              "0  0.352941  0.818182  0.256150  ...  0.469027  0.143842    0.444444\n",
              "1  0.352941  0.863636  0.256066  ...  0.256637  0.143842    0.444444\n",
              "2  0.352941  0.772727  0.222301  ...  0.469027  0.143842    0.444444\n",
              "3  0.352941  0.863636  0.306839  ...  0.265487  0.143842    0.444444\n",
              "4  0.352941  0.863636  0.281478  ...  0.256637  0.143842    0.444444\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vEC1U3YD8Cu"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dsU79BHYD8Cu"
      },
      "source": [
        "X = df_scl_oe.drop(['price'], axis=1)\n",
        "y = df_scl_oe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.45, random_state=22)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE3LR0S3D8Cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960e5cde-21db-480a-ee39-20799088d90c"
      },
      "source": [
        "model_6 = LinearRegression()\n",
        "\n",
        "model_6.fit(X_train, y_train)\n",
        "preds = model_6.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_6.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.05\n",
            "R^2: 0.784\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMyQ9EHXD8Cv"
      },
      "source": [
        "### Caso 7\n",
        "\n",
        "#### Caso 5: Entrenar con un 80% (Codificación Ordinal, MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv_AaUR0D8Cv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c778e2eb-5e06-4c65-e569-b4853aa1ed17"
      },
      "source": [
        "oe = OrdinalEncoder()\n",
        "df_oe = df.copy()\n",
        "df_oe[str_categ] = oe.fit_transform(df_oe[str_categ])\n",
        "\n",
        "x = df_oe.values #returns a numpy array\n",
        "min_max_scaler = MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df_scl_oe = pd.DataFrame(x_scaled, columns=df_oe.columns)\n",
        "df_scl_oe.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.256150</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.138100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.256066</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.106716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>0.222301</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.157479</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469027</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.306839</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.084476</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.265487</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.281478</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.208019</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.143842</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model      year     price  ...       tax       mpg  engineSize\n",
              "0  0.352941  0.818182  0.256150  ...  0.469027  0.143842    0.444444\n",
              "1  0.352941  0.863636  0.256066  ...  0.256637  0.143842    0.444444\n",
              "2  0.352941  0.772727  0.222301  ...  0.469027  0.143842    0.444444\n",
              "3  0.352941  0.863636  0.306839  ...  0.265487  0.143842    0.444444\n",
              "4  0.352941  0.863636  0.281478  ...  0.256637  0.143842    0.444444\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwvJv-e2D8Cv"
      },
      "source": [
        "#### Separación de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lR5H0nZpD8Cv"
      },
      "source": [
        "X = df_scl_oe.drop(['price'], axis=1)\n",
        "y = df_scl_oe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5AlhMYVD8Cv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affe8502-a427-4540-deb5-078d777531d4"
      },
      "source": [
        "model_7 = LinearRegression()\n",
        "\n",
        "model_7.fit(X_train, y_train)\n",
        "preds = model_7.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "rs = model_7.score(X_test, y_test)\n",
        "print(f'RMSE: {round(rmse,3)}')\n",
        "print(f'R^2: {round(rs,3)}\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.05\n",
            "R^2: 0.787\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67JZY4bEXd_M"
      },
      "source": [
        "# Análisis\n",
        "\n",
        "###  Resultados R2 score\n",
        "\n",
        "|         | Min Max | Robust |\n",
        "|---------|---------|--------|\n",
        "| One-Hot | 0.917   | 0.917  |\n",
        "| Ordinal | 0.787   | 0.787  |\n",
        "\n",
        "###  Resultados RMSE\n",
        "|         | Min Max | Robust |\n",
        "|---------|---------|--------|\n",
        "| One-Hot | 0.031   | 0.031  |\n",
        "| Ordinal | 0.05    | 0.444  |\n",
        "\n",
        "\n",
        "Las tablas anteriores resumen los resultados obtenidos en los primeros 4 experimentos. Es fácil evidenciar que para las dos métricas en cuestión el tipo de scaler no afecta de manera significativa las métricas, dado que en solo 1 de los 4 casos hay una diferencia entre los resultados con Min-Max y Robust scaler.  \n",
        "\n",
        "Sin embargo, el tipo de codificación hace una gran diferencia en los resultados obtenidos, para todos los casos usar One-Hot encoder mejora las métricas, ya que representa un error cuatrático medio menor y un R2 cercano a 1, lo cual indica que el ajuste lineal obtenido con el modelo de regresión es mucho mejor que con codificación ordinal. Consideramos que esto se debe a la naturaleza de las variables, por ejemplo, cuando codificamos la característica modelo con One-Hot, cada una de las características generadas representa la pertenencia del automóvil a algún tipo de modelo en específico. Sin embargo, al utilizar Ordinal Encoding todos los modelos están condensados en una única característica con diferentes valores numéricos para cada uno de ellos. Esto puede traer problemas, por ejemplo, si dos modelos obtienen valores numéricos cercanos estamos diciendo que de alguna manera estos modelos son más parecidos entre sí comparados con otro modelo de carro que recibió un valor numérico alejado, para este tipo de variables categóricas esta información no hace ningún sentido, mientras que para variables numéricas sí. Por ejemplo, tiene sentido afirmar que los carros manufacturados en años cercanos son más similares entre sí que al compararlos con modelos mucho más antiguos o modernos.\n",
        "\n",
        "Esto nos lleva a la conclusión de que en muchas ocasiones el espacio de representación de los datos es mucho más importante que el modelo en sí, dado que podemos obtener resultados mucho mejores con el mismo modelo al mejorar dicho espacio de representación.\n",
        "\n",
        "## Resultados con diferentes tamaños para el conjunto de entrenamiento.  \n",
        "\n",
        "| Datos de entrenamiento (%) | R2    | RMSE  |\n",
        "| -------------------------- | ----- | ----- |\n",
        "| 30                         | 0.785 | 0.049 |\n",
        "| 55                         | 0.784 | 0.05  |\n",
        "| 80                         | 0.787 | 0.05  |\n",
        "\n",
        "\n",
        "Como se puede ver en los resultados anteriores, entrenar con más datos mejora los resultados obtenidos, sin embargo, esta mejora no es significativa y tampoco es consistente para las dos métricas. Consideramos que para ESTE CASO EN ESPECÍFICO, estas diferencias son debido a pequeñas diferencias en los puntos en los que converge el algoritmo de optimización, pero en general tener más datos de entrenamiento es conveniente puesto que ayuda a reducir el sobreajuste de los modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZw5o8O_D8Cw"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "Se realiza la implementación del método Descenso de Gradiente estocástico. Para esta ocasión se emplea codificación One-Hot, RobustScaler y se realiza el entrenamiento a partir del 80% de los datos. Al final del entrenamiento, en la lista *errores* se tienen los valores de la función de error para cada iteración y así poder observar el progreso gráficamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il_tJAUSD8Cw"
      },
      "source": [
        "df_ohe = pd.get_dummies(df)\n",
        "scaler = RobustScaler()\n",
        "df_scl_ohe = scaler.fit_transform(df_ohe)\n",
        "df_scl_ohe = pd.DataFrame(df_scl_ohe, columns = df_ohe.columns)\n",
        "\n",
        "X = df_scl_ohe.drop(['price'], axis=1)\n",
        "y = df_scl_ohe['price']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lG3rgpZtD8Cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbcebe6-e7c7-4a0d-fe73-937b2b975550"
      },
      "source": [
        "import random\n",
        "X_train_array = np.c_[np.ones(X_train.values.shape[0]), X_train.values]\n",
        "y_train_array = y_train.values\n",
        "X_test_array = np.c_[np.ones(X_test.values.shape[0]), X_test.values]\n",
        "y_test_array = y_test.values\n",
        "\n",
        "#Inicialización de w\n",
        "w0 = np.random.rand(X_train_array.shape[1], 1)\n",
        "w = w0.copy()\n",
        "#Selección de par aleatorio\n",
        "i = random.randint(0, X_train.shape[0]-1)\n",
        "xActual = np.expand_dims(X_train_array[i], 1)\n",
        "yActual = y_train_array[i]\n",
        "#Inicialización de criterio de parada\n",
        "eps = 0.01 # Se define un criterio de parada basado en el error en la predicción #\n",
        "error = float('inf') # Valor inicial, se debe actualizar en cada iteración #\n",
        "#Inicialización de valor de la tasa de aprendizaje \n",
        "tasa = 0.001\n",
        "#Lista para monitorear aprendizaje\n",
        "errores = [] # Agregar a esta lista los valores de la función de error en cada iteración #\n",
        "old_w = w.copy()\n",
        "#Ciclo iterativo según algoritmo de descenso de gradiente\n",
        "diff_norm = float('inf')\n",
        "while diff_norm>eps:\n",
        "    train_index = list(range(0, X_train_array.shape[0]-1))\n",
        "    random.shuffle(train_index)\n",
        "    y_pred = list()\n",
        "    y_target = list()\n",
        "    for i in train_index:\n",
        "        xActual = np.expand_dims(X_train_array[i], 1)\n",
        "        yActual = y_train_array[i]\n",
        "        g = np.dot(w.T, xActual)\n",
        "        e = g-yActual\n",
        "        w = w - tasa*e*xActual\n",
        "        y_pred.append(g[0][0])\n",
        "        y_target.append(yActual)\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_target = np.array(y_target)\n",
        "    error = mean_squared_error(y_target, y_pred)\n",
        "    errores.append(error)\n",
        "    \n",
        "    diff = old_w-w\n",
        "    diff_norm = np.sqrt(diff.T.dot(diff))[0][0]\n",
        "    print(\"Error\", error, \"Diff \", diff_norm)\n",
        "    old_w = w.copy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error 0.3648801396270797 Diff  1.2055050658360833\n",
            "Error 0.1648827229936493 Diff  0.34176900977986346\n",
            "Error 0.13717278071759417 Diff  0.21734901130804848\n",
            "Error 0.12297934642823441 Diff  0.17027649167015416\n",
            "Error 0.11475124612358849 Diff  0.13781001903743675\n",
            "Error 0.10886713015420912 Diff  0.1142895415909546\n",
            "Error 0.10405284928379785 Diff  0.10142789766840085\n",
            "Error 0.10134617009653098 Diff  0.09211464956430056\n",
            "Error 0.09889775734276461 Diff  0.0827008244683007\n",
            "Error 0.09729434884913428 Diff  0.0678407453939031\n",
            "Error 0.09586422558340536 Diff  0.07241092229857204\n",
            "Error 0.09446273426501595 Diff  0.061796498153395454\n",
            "Error 0.09341955584128056 Diff  0.05579701275371109\n",
            "Error 0.09235473291337469 Diff  0.05248063261060142\n",
            "Error 0.09152795546504568 Diff  0.052540945439265775\n",
            "Error 0.09075287646255269 Diff  0.04830853966166401\n",
            "Error 0.08986410358523983 Diff  0.047611402049867343\n",
            "Error 0.08913981339669493 Diff  0.04466255547813613\n",
            "Error 0.08839390302317783 Diff  0.059877579727197046\n",
            "Error 0.08801669492764155 Diff  0.046262970940842654\n",
            "Error 0.08719778717732475 Diff  0.040727857762305135\n",
            "Error 0.08691901436806394 Diff  0.040162006299038676\n",
            "Error 0.08636348495655326 Diff  0.041861488267428165\n",
            "Error 0.0854086192807263 Diff  0.038939339913130235\n",
            "Error 0.08538274346941709 Diff  0.043133089558102765\n",
            "Error 0.08485186283857563 Diff  0.04402184127029513\n",
            "Error 0.08431239438597898 Diff  0.03592595121585287\n",
            "Error 0.08395709461114285 Diff  0.03429466282454686\n",
            "Error 0.08355688597165781 Diff  0.04711257814470061\n",
            "Error 0.08297064034334488 Diff  0.04613538076630997\n",
            "Error 0.08252547743188558 Diff  0.03432287644315298\n",
            "Error 0.08242288564683085 Diff  0.03994523474698387\n",
            "Error 0.0819094883784111 Diff  0.043150724229401936\n",
            "Error 0.08179154476205436 Diff  0.05092188514419777\n",
            "Error 0.08156413915008975 Diff  0.033649074179040596\n",
            "Error 0.08116781635435873 Diff  0.03666369728208457\n",
            "Error 0.08068261297014291 Diff  0.030607787505292704\n",
            "Error 0.08017679579539275 Diff  0.030647866783026008\n",
            "Error 0.08012156979395041 Diff  0.036775176947938075\n",
            "Error 0.07992666760196593 Diff  0.03248434596059432\n",
            "Error 0.0795906776844241 Diff  0.02875071870818348\n",
            "Error 0.07932981442487497 Diff  0.03507139248888496\n",
            "Error 0.07916731913265351 Diff  0.032339535255162706\n",
            "Error 0.07871589705066573 Diff  0.031976200300009944\n",
            "Error 0.07837053579156782 Diff  0.04725562170602745\n",
            "Error 0.0781872535022873 Diff  0.044481039871002576\n",
            "Error 0.07764107741070228 Diff  0.0571797420419322\n",
            "Error 0.07786090037388668 Diff  0.03886714724105573\n",
            "Error 0.0774329613135841 Diff  0.034479933010139505\n",
            "Error 0.07724644278630718 Diff  0.03979854286215883\n",
            "Error 0.0769923539138315 Diff  0.02890262828003387\n",
            "Error 0.07692015488236605 Diff  0.03327363511234445\n",
            "Error 0.07615423681845473 Diff  0.03894243015170666\n",
            "Error 0.07638300455311901 Diff  0.044778043468649616\n",
            "Error 0.07579647450199535 Diff  0.029387940670617892\n",
            "Error 0.0759745253787889 Diff  0.03312994014688009\n",
            "Error 0.07564343569877237 Diff  0.054887758853022925\n",
            "Error 0.07544728143764046 Diff  0.04299124708872223\n",
            "Error 0.07511734730602658 Diff  0.031444703077678604\n",
            "Error 0.07510031053661143 Diff  0.02317213222264709\n",
            "Error 0.0748179103020057 Diff  0.02870627179729714\n",
            "Error 0.07482366832662715 Diff  0.036075632301915204\n",
            "Error 0.07464905278863779 Diff  0.03364854751266322\n",
            "Error 0.07407489619549926 Diff  0.03601494319910949\n",
            "Error 0.07412828164282569 Diff  0.03649813455609735\n",
            "Error 0.07412213835655054 Diff  0.026526725451198222\n",
            "Error 0.07354299321685699 Diff  0.03241011848134355\n",
            "Error 0.07377432600282302 Diff  0.024910381429938136\n",
            "Error 0.07313076668506038 Diff  0.02999595143168561\n",
            "Error 0.0733279801414559 Diff  0.03500960534343001\n",
            "Error 0.07323890967009582 Diff  0.025707602195651727\n",
            "Error 0.07283165651622116 Diff  0.035299013635602824\n",
            "Error 0.07234113155870452 Diff  0.031957038907276816\n",
            "Error 0.07255053321322247 Diff  0.049573463473437086\n",
            "Error 0.07229862136118304 Diff  0.032988643599161545\n",
            "Error 0.07238649942469072 Diff  0.034856854736853356\n",
            "Error 0.07227989301189161 Diff  0.028734690289065345\n",
            "Error 0.07183319194036021 Diff  0.024425691835839515\n",
            "Error 0.07188090365612511 Diff  0.026039450131266153\n",
            "Error 0.07173396688940538 Diff  0.0322253708348886\n",
            "Error 0.07173547936109016 Diff  0.02378265259559977\n",
            "Error 0.07133791823498202 Diff  0.029330604912336626\n",
            "Error 0.07140483071574599 Diff  0.027171071224273688\n",
            "Error 0.07132037944714627 Diff  0.020408218386025374\n",
            "Error 0.0709616229481038 Diff  0.033992242529494676\n",
            "Error 0.07116311213207083 Diff  0.029955100933006802\n",
            "Error 0.07103641787799266 Diff  0.02116690109023127\n",
            "Error 0.07069658754514291 Diff  0.02612480036263196\n",
            "Error 0.07068123114419184 Diff  0.034103531958715363\n",
            "Error 0.07050728461956222 Diff  0.04368349710428186\n",
            "Error 0.07037010034681296 Diff  0.03273111411448101\n",
            "Error 0.0701456923465579 Diff  0.02144226140245115\n",
            "Error 0.07013205843817244 Diff  0.018581930584760792\n",
            "Error 0.07002995814426097 Diff  0.02489857948174226\n",
            "Error 0.06977845173219123 Diff  0.018927172949292356\n",
            "Error 0.06991969288102459 Diff  0.02562661605944555\n",
            "Error 0.06950515745971449 Diff  0.024910656001203506\n",
            "Error 0.06968164029142423 Diff  0.029972697672956163\n",
            "Error 0.06945605044228965 Diff  0.021891038978524267\n",
            "Error 0.0691531586405178 Diff  0.027545160745918052\n",
            "Error 0.06908964610336846 Diff  0.028060063357587827\n",
            "Error 0.06903454819264247 Diff  0.027026217767453446\n",
            "Error 0.06918526268994392 Diff  0.0248215398385871\n",
            "Error 0.06894958928396396 Diff  0.025506871484671498\n",
            "Error 0.06878825161410206 Diff  0.021385936358343148\n",
            "Error 0.06878441033947909 Diff  0.034141546723475275\n",
            "Error 0.06870246488020028 Diff  0.02986946255578236\n",
            "Error 0.06869344831550599 Diff  0.02619702178623276\n",
            "Error 0.06854894253612498 Diff  0.027288859084485268\n",
            "Error 0.06851587857832572 Diff  0.020622078197954568\n",
            "Error 0.06845143307679322 Diff  0.01883582844264464\n",
            "Error 0.06835897020947893 Diff  0.020314127934985916\n",
            "Error 0.06805959401179161 Diff  0.0287184419829028\n",
            "Error 0.06820949193987295 Diff  0.029592050511419794\n",
            "Error 0.06774144738234128 Diff  0.02404600174542791\n",
            "Error 0.06792932729671552 Diff  0.025133065222451706\n",
            "Error 0.06797008069752877 Diff  0.03654581533328495\n",
            "Error 0.06768706037355171 Diff  0.030289317433766012\n",
            "Error 0.06775697998058716 Diff  0.029130742940572576\n",
            "Error 0.06760700151736712 Diff  0.021600563711820175\n",
            "Error 0.06754915324227197 Diff  0.02645979437183417\n",
            "Error 0.06747962589610901 Diff  0.018946318073665345\n",
            "Error 0.06757486322780538 Diff  0.026509460041501336\n",
            "Error 0.06756067625501182 Diff  0.019552528440751074\n",
            "Error 0.06738023952145968 Diff  0.018243414594705454\n",
            "Error 0.0671111206446315 Diff  0.026261817086168423\n",
            "Error 0.06700095184061303 Diff  0.018755730954265734\n",
            "Error 0.06678686678248237 Diff  0.0522084641051389\n",
            "Error 0.06730350954813837 Diff  0.03623471159038211\n",
            "Error 0.06718490515416838 Diff  0.01527224068671727\n",
            "Error 0.06695387392889605 Diff  0.01945150256943872\n",
            "Error 0.06666936571402282 Diff  0.01674941429350032\n",
            "Error 0.06674968940086555 Diff  0.01912286083885066\n",
            "Error 0.06683886051937656 Diff  0.024313669839907504\n",
            "Error 0.06681680396550134 Diff  0.02392089884389836\n",
            "Error 0.06647764388770963 Diff  0.02813302350014821\n",
            "Error 0.0667667721509458 Diff  0.02325592953453268\n",
            "Error 0.06608372001214569 Diff  0.05132029207562903\n",
            "Error 0.06652849622225163 Diff  0.05128707476697829\n",
            "Error 0.06616721118431983 Diff  0.02728628434935052\n",
            "Error 0.06607668483762001 Diff  0.02845997493497711\n",
            "Error 0.06580237950530914 Diff  0.05175752584918799\n",
            "Error 0.06626267205986328 Diff  0.028540250632338005\n",
            "Error 0.06607470711908144 Diff  0.021123526193385932\n",
            "Error 0.06612671085803434 Diff  0.0153095683397568\n",
            "Error 0.06608002149748203 Diff  0.031975613899867\n",
            "Error 0.06592144887501893 Diff  0.035567102192477315\n",
            "Error 0.06608517264146799 Diff  0.033465131808500616\n",
            "Error 0.06562025881144952 Diff  0.030916944708086164\n",
            "Error 0.06570394874791437 Diff  0.029579149829052694\n",
            "Error 0.0658070919407482 Diff  0.01887718297881149\n",
            "Error 0.0657687608999893 Diff  0.026400031700790572\n",
            "Error 0.06577443051697984 Diff  0.04488455632010758\n",
            "Error 0.06570828454122657 Diff  0.015823807943201686\n",
            "Error 0.06591040945466885 Diff  0.03251187803113565\n",
            "Error 0.06559853820258843 Diff  0.018708074540914162\n",
            "Error 0.06546216035065831 Diff  0.02484395075734537\n",
            "Error 0.06557426759426839 Diff  0.015190732855238\n",
            "Error 0.06566602290060458 Diff  0.027192408230132876\n",
            "Error 0.06546526139132126 Diff  0.0345706650346306\n",
            "Error 0.06547182548037911 Diff  0.03214842487210786\n",
            "Error 0.0651519482211624 Diff  0.03455298509003508\n",
            "Error 0.06535953959525738 Diff  0.039767437093017874\n",
            "Error 0.06525923161130222 Diff  0.019267206981955096\n",
            "Error 0.06532323747620543 Diff  0.015246208487362387\n",
            "Error 0.06508061281512637 Diff  0.02073219617676425\n",
            "Error 0.06492023142877432 Diff  0.05872820380182519\n",
            "Error 0.06501287151601123 Diff  0.03802635282841645\n",
            "Error 0.06503706826646792 Diff  0.028882286353258218\n",
            "Error 0.0651423902061736 Diff  0.028582576828575443\n",
            "Error 0.06525085453613787 Diff  0.019647532311836025\n",
            "Error 0.0652457338060648 Diff  0.01970159162428833\n",
            "Error 0.0650139735682407 Diff  0.0246242894698991\n",
            "Error 0.06503855440834368 Diff  0.01627022711266662\n",
            "Error 0.06488019176311445 Diff  0.027736165817144737\n",
            "Error 0.06494502568251102 Diff  0.030062923745930916\n",
            "Error 0.06488419607222275 Diff  0.022019504697001726\n",
            "Error 0.06492360569180351 Diff  0.024346443210617515\n",
            "Error 0.06490027432732921 Diff  0.02051098282877075\n",
            "Error 0.06451979276903504 Diff  0.030016506130622587\n",
            "Error 0.06430413593016573 Diff  0.03233218384163003\n",
            "Error 0.06438493725927168 Diff  0.06981924341584768\n",
            "Error 0.06509508598639155 Diff  0.034381785471294654\n",
            "Error 0.06467754185146736 Diff  0.02345343554849302\n",
            "Error 0.0647087484439176 Diff  0.02927091421199413\n",
            "Error 0.06473047534669207 Diff  0.020072268591872007\n",
            "Error 0.0647854550715363 Diff  0.014538230454536115\n",
            "Error 0.06449432136105175 Diff  0.028301222144493137\n",
            "Error 0.06470852545003151 Diff  0.02215306889226502\n",
            "Error 0.0645036820304091 Diff  0.024410468039417748\n",
            "Error 0.06440884575644897 Diff  0.03228620856522559\n",
            "Error 0.06435833923996598 Diff  0.021452087024355013\n",
            "Error 0.06442358772115372 Diff  0.028269131081525407\n",
            "Error 0.06449448427447968 Diff  0.018814969169673776\n",
            "Error 0.06439084671842374 Diff  0.030683437183451786\n",
            "Error 0.06439287890769724 Diff  0.023730521511945497\n",
            "Error 0.0644985585616599 Diff  0.011145823390007107\n",
            "Error 0.06443024296625376 Diff  0.019059371680838388\n",
            "Error 0.06448819825574394 Diff  0.013814665734040003\n",
            "Error 0.06423387809267586 Diff  0.031028940797964782\n",
            "Error 0.06411955855515011 Diff  0.027042921563792958\n",
            "Error 0.06444761527350049 Diff  0.012639148742643028\n",
            "Error 0.06415880026656075 Diff  0.02394066537761994\n",
            "Error 0.06426691595668058 Diff  0.026491156588421733\n",
            "Error 0.06374652296278419 Diff  0.04926831555025242\n",
            "Error 0.06447495662590873 Diff  0.03594998225594342\n",
            "Error 0.06436359338548706 Diff  0.016278573978497985\n",
            "Error 0.06386922810667418 Diff  0.02297924943648406\n",
            "Error 0.06414378454220288 Diff  0.03190142174496322\n",
            "Error 0.06390304570851073 Diff  0.02527711453609769\n",
            "Error 0.06408476782852811 Diff  0.01782772299153263\n",
            "Error 0.06421286387324592 Diff  0.012656491403169675\n",
            "Error 0.0638713059370177 Diff  0.018506290031620205\n",
            "Error 0.06421112588186041 Diff  0.02554573274521708\n",
            "Error 0.06393803043887523 Diff  0.030996754628341\n",
            "Error 0.06372948193126464 Diff  0.03595766193366427\n",
            "Error 0.06403327559973895 Diff  0.03153557813554858\n",
            "Error 0.06418045539864842 Diff  0.01948720059066057\n",
            "Error 0.06370982525778578 Diff  0.025956631187217527\n",
            "Error 0.06382895760055249 Diff  0.043114265536074836\n",
            "Error 0.06409785276693307 Diff  0.03399360558468888\n",
            "Error 0.06371576853737379 Diff  0.02877450996894249\n",
            "Error 0.06402251533997902 Diff  0.03433262112318372\n",
            "Error 0.0637346228697092 Diff  0.02460780049537204\n",
            "Error 0.0638549372582252 Diff  0.03582979218942711\n",
            "Error 0.0636581787728025 Diff  0.02429743587681215\n",
            "Error 0.0638648435237019 Diff  0.01736086192346993\n",
            "Error 0.06385096857031688 Diff  0.027428922273987116\n",
            "Error 0.06375331060234489 Diff  0.015551155457869047\n",
            "Error 0.06364639433685472 Diff  0.025901845635678284\n",
            "Error 0.06365863634604858 Diff  0.026300946166715015\n",
            "Error 0.06385750291641643 Diff  0.0186539189921682\n",
            "Error 0.0637239664870422 Diff  0.023547576738256533\n",
            "Error 0.06364487787368675 Diff  0.024796100583538327\n",
            "Error 0.06365231879710354 Diff  0.015716626088642036\n",
            "Error 0.0633701021094074 Diff  0.01247444039203868\n",
            "Error 0.06349216385543692 Diff  0.014252360076746082\n",
            "Error 0.06338914172351368 Diff  0.03859285998950693\n",
            "Error 0.06370931188849303 Diff  0.05201348091457916\n",
            "Error 0.06343445982459488 Diff  0.009024546899144064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tijtkT6pbhwM"
      },
      "source": [
        "Para la implementación del algoritmo de gradiente de descenso estocástico utilizamos como criterio de parada la diferencia entre dos vectores de pesos consecutivos, nuestra implementación del algoritmo obtiene resultados comparables a la implementación de la librería Scikit-Learn. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCZ_oxxD8Cx"
      },
      "source": [
        "#### Evaluación de Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrfiXceVD8Cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cea4925-57d6-489b-cd57-7dd8ec42fa22"
      },
      "source": [
        "y_train_preds = np.zeros(y_train_array.shape)\n",
        "for i in range(X_train_array.shape[0]):\n",
        "    y_train_preds[i] = np.dot(w.T,X_train_array[i])\n",
        "\n",
        "y_test_preds = np.zeros(y_test_array.shape)\n",
        "for i in range(X_test_array.shape[0]):\n",
        "    y_test_preds[i] = np.dot(w.T,X_test_array[i])\n",
        "    \n",
        "r2_train = r2_score(y_train_array, y_train_preds)\n",
        "r2_test = r2_score(y_test_array, y_test_preds)\n",
        "print(f'R2 entrenamiento: {round(r2_train,4)}\\nR2 prueba: {round(r2_test,4)}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 entrenamiento: 0.9288\n",
            "R2 prueba: 0.9147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6DmOR2TD8Cy"
      },
      "source": [
        "## Gráfica de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tahhiR7GD8Cy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "9e76d7db-adb5-4517-d3bc-4d270bb9eb6f"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(errores)\n",
        "plt.xlabel('# Iteraciones')\n",
        "plt.ylabel('Función de Error')\n",
        "plt.title('Descenso de Gradiente Estocástico')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Descenso de Gradiente Estocástico')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA31irmTa0F5"
      },
      "source": [
        "## Seleccion de parametros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8i_P-hVQ28v"
      },
      "source": [
        "def train_linear_regression(X_train, y_train, learning_rate, eps):\n",
        "    X_train_array = np.c_[np.ones(X_train.values.shape[0]), X_train.values]\n",
        "    y_train_array = y_train.values\n",
        "    w0 = np.random.rand(X_train_array.shape[1], 1)\n",
        "    w = w0.copy()\n",
        "    errores = list()\n",
        "    diff_norm = float('inf')\n",
        "    old_w = w.copy()\n",
        "    while diff_norm>eps:\n",
        "      # Ordenamos las muestras de manera aleatoria.\n",
        "      train_index = list(range(0, X_train_array.shape[0]-1))\n",
        "      random.shuffle(train_index)\n",
        "      y_pred = list()\n",
        "      y_target = list()\n",
        "      # Iteramos sobre la muestras.\n",
        "      for i in train_index:\n",
        "        # Actualizamos los pesos de acuerdo al algoritmo.\n",
        "          xActual = np.expand_dims(X_train_array[i], 1)\n",
        "          yActual = y_train_array[i]\n",
        "          g = np.dot(w.T, xActual)\n",
        "          e = g-yActual\n",
        "          w = w - learning_rate*e*xActual\n",
        "          y_pred.append(g[0][0])\n",
        "          y_target.append(yActual)\n",
        "      y_pred = np.array(y_pred)\n",
        "      y_target = np.array(y_target)\n",
        "      error = mean_squared_error(y_target, y_pred)\n",
        "      errores.append(error)\n",
        "      # Computamos la diferencia entre los W nuevos y los antiguos\n",
        "      diff = old_w-w\n",
        "      diff_norm = np.sqrt(diff.T.dot(diff))[0][0]\n",
        "      old_w = w.copy()\n",
        "    return w, errores"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EmiY7ErSIOx"
      },
      "source": [
        "w_exp1, errores_exp1 = train_linear_regression(X_train, y_train, 0.001, 0.01)\n",
        "w_exp2, errores_exp2 = train_linear_regression(X_train, y_train, 0.01, 0.08)\n",
        "w_exp3, errores_exp3 = train_linear_regression(X_train, y_train, 0.0001, 0.0050)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "RKqNVj99WsiQ",
        "outputId": "70044261-1f54-4abd-95f0-7fc303028401"
      },
      "source": [
        "plt.plot(errores_exp1)\n",
        "plt.title(f\"Learning rate {0.001}\")\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "SBaGShPJVEmx",
        "outputId": "94a2d101-939d-4ca4-d3af-2b14d8b6c90e"
      },
      "source": [
        "plt.plot(errores_exp2)\n",
        "plt.title(f\"Learning rate {0.01}\")\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Kt7tGROuNVcS",
        "outputId": "bc5b8889-ee86-4317-fc07-885e0042308b"
      },
      "source": [
        "plt.plot(errores_exp3)\n",
        "plt.title(f\"Learning rate {0.0001}\")\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpvm_RJKZEHm"
      },
      "source": [
        "def test_model(model, X_train, X_test, y_train, y_test):\n",
        "  y_train_array = y_train.values\n",
        "  y_test_array = y_test.values\n",
        "  y_train_preds = np.zeros(y_train_array.shape)\n",
        "  for i in range(X_train_array.shape[0]):\n",
        "      y_train_preds[i] = np.dot(model.T,X_train_array[i])\n",
        "\n",
        "  y_test_preds = np.zeros(y_test_array.shape)\n",
        "  for i in range(X_test_array.shape[0]):\n",
        "      y_test_preds[i] = np.dot(model.T,X_test_array[i])\n",
        "      \n",
        "  r2_train = r2_score(y_train_array, y_train_preds)\n",
        "  r2_test = r2_score(y_test_array, y_test_preds)\n",
        "  print(f'R2 entrenamiento: {round(r2_train,4)}\\nR2 prueba: {round(r2_test,4)}')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnTr5dVbGdr"
      },
      "source": [
        "## Resultados modelo learning rate 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9noLfydZ3Ij",
        "outputId": "283c3e2f-5dd1-4f41-ce29-cfde7ba1e337"
      },
      "source": [
        "test_model(w_exp1, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 entrenamiento: 0.9285\n",
            "R2 prueba: 0.9143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hm39EK3bS1h"
      },
      "source": [
        "## Resultados modelo learning rate 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTW_C9avaZKS",
        "outputId": "960aa9de-c62e-4759-8ad5-ab3f51418b34"
      },
      "source": [
        "test_model(w_exp2, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 entrenamiento: 0.9246\n",
            "R2 prueba: 0.911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpJRi94hbXU4"
      },
      "source": [
        "## Resultados modelo learning rate 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrp1-F8sagt6",
        "outputId": "723b08f5-ee4f-4dcc-95b6-c364fdca246c"
      },
      "source": [
        "test_model(w_exp3, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 entrenamiento: 0.8964\n",
            "R2 prueba: 0.8939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPnUJq5XavwQ"
      },
      "source": [
        "Para la seleccion de modelo probamos con diferentes valores de la tasa de aprendizaje, como se puede ver en las _learning curves_ anteriores,  el learning rate mas alto (0.01) tiene un comportamineto \"ruidoso\" esto puede deberse a que es un valor muy alto y el algoritmo oscila sobre el minimo pero jamas logra acercarce tanto comos los modelos que usan pasos menores. Por otro lado, al comparar las curvas de aprendizaje para los learning rate 0.001, 0.0001 es evidente que el tamaño del paso afecta al velocidad de convergencia.\n",
        "\n",
        "Sin embargo, los resultados en los datos de pruebas de los tres modelos son bastante similares y las diferencias en la tasa de aprendizaje para este caso no ayudan de manera signifcativa al desempeño de los modelos.\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "* El acondicionamiento de los datos es muy importante para obtener buenos resultados, donde se pudo evidenciar que con un mismo modelo puede variar el valor de las métricas de acuerdo con el tipo de scaler y de codificación.  \n",
        "\n",
        "* Aunque con este grupo de datos la variación de métricas es pequeña al variar la cantidad de datos de entrenamiento, a nivel general, entrenar con mayor cantidad de datos es deseable para reducir el sobreajuste de los datos.\n",
        "\n",
        "* La codificación por medio de one hot amplía el número de variables de entrenamiento, se podría pensar que esto afecta negativamente a los entrenamientos al ampliar su complejidad o dimensionalidad en cuanto a variables, sin embargo, los resultados obtenidos nos dicen que es mucho más facil para un modelo de regresión lineal obtener un mejor modelo de esta forma que manteniendo el número de variables pero convirtiendo las categóricas en númericas, como funciona con la codificación ordinal.\n",
        "\n",
        "* El scaler MinMax y Robust pueden funcionar mejor uno u otro dependiendo de los datos y del problema a solucionar, el Robust modifica la distribución de los datos, eliminando outlayers, por ende puede funcionar mejor ante datos con esta característica, sin embargo, el MinMax demostró ser el mejor en la codificaión ordinal en la métrica RMSE, por ende se podría concluir que la data empleada se encontraba libre de outlayers y que ante datos no muy complejos el MinMax tiene mucho mejor resultado frente al Robust.\n",
        "\n",
        "\n",
        "* La implementación de descenso de gradiente estocástico fue realizada empleando como criterio de parada la diferencia entre dos vectores de pesos consecutivos, nuestra implementación del algoritmo obtiene resultados tan buenos como los que se obtienen por medio de la librería Scikit-Learn, ya que el R2 obtenido para test en ambos casos es 0.917, donde, como se observa en la gráfica, se logra una convergencia del error muy buena y rápida, ya que en las primeras 20 iteraciones se logra una reducción del error muy significativa y esta continúa descendiendo en el tiempo hasta lograr cumplir con el criterio de parada. \n",
        "\n",
        "* Al cambiar la tasa de aprendizaje tambien es necesario cambiar el criterio de parada puesto en algunos casos no se logra convergencia en un tiempo de entrenamiento razonable o en ocaciones la magnitud \n",
        "\n",
        "# Referencias\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
        "\n",
        "https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "\n",
        "https://www.kaggle.com/discdiver/guide-to-scaling-and-standardizing"
      ]
    }
  ]
}