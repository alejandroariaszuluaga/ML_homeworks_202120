{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntaje Bancario: Aprobación de Crédito Mediante Redes Neuronales\n",
    "\n",
    "En esta ocasión se busca desarrollar un protocolo de pruebas que permita encontrar la mejor arquitectura de red neuronal completamente conectada. En esta ocasión debe utilizar la librería SciKit-Learn (sklearn.neural_network) para diseñar cada red. Además, veremos algunos conceptos de _feature engineering_ para analizar los datos a nuestra disposición.\n",
    "\n",
    "Debe completar las celdas vacías y seguir las instrucciones anotadas en el cuaderno.\n",
    "\n",
    "La fecha límite de entrega es el día **18 de octubre** y se realizará a través de Bloque Neón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen dos archivos:\n",
    "\n",
    "`application_record.csv`: posee información general (puede observar los nombres de las columnas a continuación) sobre cada usuario, definido a partir de una ID única.\n",
    "\n",
    "- ID: número de cliente\n",
    "- CODE_GENDER: género\n",
    "- FLAG_OWN_CAR:\tposee un automóvil\n",
    "- FLAG_OWN_REALTY: posee un inmueble\n",
    "- CNT_CHILDREN:\tcantidad de hijos\n",
    "- AMT_INCOME_TOTAL:\tingresos anuales\n",
    "- NAME_INCOME_TYPE: categoría de ingresos\n",
    "- NAME_EDUCATION_TYPE: nivel educativo\n",
    "- NAME_FAMILY_STATUS estado civil\n",
    "- NAME_HOUSING_TYPE: forma de vivienda (e.g. renta, apartamento propio, ...)\n",
    "- DAYS_BIRTH: fecha de nacimiento, en días hacia atrás desde la actualidad, -1 significa ayer\n",
    "\n",
    "- DAYS_EMPLOYED: tiempo de empleo, en días hacia atrás desde la actualidad, -1 significa ayer. Si es positivo, el usuario se encuentra desempleado.\n",
    "- FLAG_MOBIL: teléfono móvil\n",
    "- FLAG_WORK_PHONE: teléfono de trabajo\n",
    "- FLAG_PHONE: teléfono\n",
    "- FLAG_EMAIL: email\n",
    "- OCCUPATION_TYPE: ocupación\n",
    "- CNT_FAM_MEMBERS: tamaño de familia\n",
    "\n",
    "\n",
    "`credit_record.csv`:\n",
    "\n",
    "- ID: número de cliente\n",
    "- MONTHS_BALANCE: mes de registro\n",
    "- ESTADO:\n",
    "    - 0: 1-29 días atrasados\n",
    "    - 1: 30-59 días atrasados\n",
    "    - 2: 60-89 días atrasados\n",
    "    - 3: 90-119 días atrasados\n",
    "    - 4: 120-149 días atrasados\n",
    "    - 5: Atrasados o incobrables, cancelaciones durante más de 150 días\n",
    "    - C: cancelado ese mes X: sin préstamo durante el mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditCardScore/application_record.csv\", encoding = 'utf-8') \n",
    "record = pd.read_csv(\"creditCardScore/credit_record.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetas\n",
    "\n",
    "Inicialmente, se concatenan ambas tablas mediante el tiempo de registro máximo (`MONTHS_BALANCE`) y la ID del cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all users' account open month.\n",
    "begin_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "new_data=pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los usuarios con mora durante más de 60 días se etiquerarán como `1`, de lo contrario, serán `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['dep_value'] = None\n",
    "record['dep_value'][record['STATUS'] =='2']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='3']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='4']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='5']='Yes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpunt=record.groupby('ID').count()\n",
    "cpunt['dep_value'][cpunt['dep_value'] > 0]='Yes' \n",
    "cpunt['dep_value'][cpunt['dep_value'] == 0]='No' \n",
    "cpunt = cpunt[['dep_value']]\n",
    "new_data=pd.merge(new_data,cpunt,how='inner',on='ID')\n",
    "new_data['target']=new_data['dep_value']\n",
    "new_data.loc[new_data['target']=='Yes','target']=1\n",
    "new_data.loc[new_data['target']=='No','target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpunt['dep_value'].value_counts())\n",
    "cpunt['dep_value'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proporción de clases.\n",
    "\n",
    "### Descriptores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Renombramiento de las Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns={'CODE_GENDER':'Gender','FLAG_OWN_CAR':'Car','FLAG_OWN_REALTY':'Reality',\n",
    "                         'CNT_CHILDREN':'ChldNo','AMT_INCOME_TOTAL':'inc',\n",
    "                         'NAME_EDUCATION_TYPE':'edutp','NAME_FAMILY_STATUS':'famtp',\n",
    "                        'NAME_HOUSING_TYPE':'houtp','FLAG_EMAIL':'email',\n",
    "                         'NAME_INCOME_TYPE':'inctp','FLAG_WORK_PHONE':'wkphone',\n",
    "                         'FLAG_PHONE':'phone','CNT_FAM_MEMBERS':'famsize',\n",
    "                        'OCCUPATION_TYPE':'occyp'\n",
    "                        },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna()\n",
    "new_data = new_data.mask(new_data == 'NULL').dropna() # Retiramos los valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=pd.DataFrame(new_data.columns,columns=['variable'])\n",
    "ivtable['IV']=None\n",
    "namelist = ['FLAG_MOBIL','begin_month','dep_value','target','ID']\n",
    "\n",
    "for i in namelist:\n",
    "    ivtable.drop(ivtable[ivtable['variable'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crean algunas funciones que serán utilizadas más adelante.\n",
    "\n",
    "Función `calc_iv` para obtener las variables IV (information value) y WoE (weight of evidence). Estas variables, de forma general, nos permiten conocer la importancia de cada feature disponible.\n",
    "\n",
    "Puede encontrar más información en:\n",
    "- https://www.kaggle.com/puremath86/iv-woe-starter-for-python\n",
    "- https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de IV\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    print('El IV de esta variable es:',iv)\n",
    "    print(df[feature].value_counts())\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One-Hot\n",
    "def convert_dummy(df, feature,rank=0):\n",
    "    pos = pd.get_dummies(df[feature], prefix=feature)\n",
    "    mode = df[feature].value_counts().index[rank]\n",
    "    biggest = feature + '_' + str(mode)\n",
    "    pos.drop([biggest],axis=1,inplace=True)\n",
    "    df.drop([feature],axis=1,inplace=True)\n",
    "    df=df.join(pos)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(df, col, binsnum, labels, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = 'gp' + '_' + col\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusión\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta')\n",
    "    plt.xlabel('Predicción')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptores Binarios\n",
    "\n",
    "Se utilizará la función desarrollada anteriormente para realizar un análisis de cada uno de los descriptores binarios y **su influencia dentro de la predicción de cada clase**.\n",
    "\n",
    "#### Género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Gender'] = new_data['Gender'].replace(['F','M'],[0,1])\n",
    "print(new_data['Gender'].value_counts())\n",
    "iv, data = calc_iv(new_data,'Gender','target')\n",
    "ivtable.loc[ivtable['variable']=='Gender','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posesión de un Automóvil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Car'] = new_data['Car'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Car'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Car','target')\n",
    "ivtable.loc[ivtable['variable']=='Car','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posesión de un Inmueble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Reality'] = new_data['Reality'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Reality'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Reality','target')\n",
    "ivtable.loc[ivtable['variable']=='Reality','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posesión de un Teléfono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['phone']=new_data['phone'].astype(str)\n",
    "print(new_data['phone'].value_counts(normalize=True,sort=False))\n",
    "new_data.drop(new_data[new_data['phone'] == 'nan' ].index, inplace=True)\n",
    "iv, data=calc_iv(new_data,'phone','target')\n",
    "ivtable.loc[ivtable['variable']=='phone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posesión de Correo Electrónico (Email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['email'].value_counts(normalize=True,sort=False))\n",
    "new_data['email']=new_data['email'].astype(str)\n",
    "iv, data=calc_iv(new_data,'email','target')\n",
    "ivtable.loc[ivtable['variable']=='email','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posesión de Teléfono para Trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['wkphone']=new_data['wkphone'].astype(str)\n",
    "iv, data = calc_iv(new_data,'wkphone','target')\n",
    "new_data.drop(new_data[new_data['wkphone'] == 'nan' ].index, inplace=True)\n",
    "ivtable.loc[ivtable['variable']=='wkphone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptores Continuos\n",
    "\n",
    "#### Cantidad de Hijos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos aquellos que: no tienen hijos, tienen 1 hijo, tienen 2 o más hijos.\n",
    "\n",
    "new_data.loc[new_data['ChldNo'] >= 2,'ChldNo']='2More'\n",
    "print(new_data['ChldNo'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'ChldNo','target')\n",
    "ivtable.loc[ivtable['variable']=='ChldNo','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'ChldNo') # Adicionamos una Codificación One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingresos Anuales\n",
    "\n",
    "Gráfica de Histograma para observar la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['inc'] = new_data['inc'].astype(object)\n",
    "new_data['inc'] = new_data['inc']/10000 \n",
    "print(new_data['inc'].value_counts(bins=10,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['inc'].plot(kind='hist',bins=50,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'inc', 3, [\"low\",\"medium\", \"high\"], qcut = True)\n",
    "iv, data = calc_iv(new_data,'gp_inc','target')\n",
    "ivtable.loc[ivtable['variable']=='inc','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_inc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_data['Age']=-(new_data['DAYS_BIRTH'])//365\t\n",
    "print(new_data['Age'].value_counts(bins=10,normalize=True,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Age'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'Age',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data = calc_iv(new_data,'gp_Age','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','IV'] = iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Años de Trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['worktm']=-(new_data['DAYS_EMPLOYED'])//365\n",
    "new_data[new_data['worktm']<0] = np.nan # replace by na\n",
    "new_data['DAYS_EMPLOYED']\n",
    "new_data['worktm'].fillna(new_data['worktm'].mean(),inplace=True) #replace na by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['worktm'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'worktm',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data=calc_iv(new_data,'gp_worktm','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One-Hot\n",
    "new_data = convert_dummy(new_data,'gp_worktm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tamaño de Familia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize']=new_data['famsize'].astype(int)\n",
    "new_data['famsizegp']=new_data['famsize']\n",
    "new_data['famsizegp']=new_data['famsizegp'].astype(object)\n",
    "new_data.loc[new_data['famsizegp']>=3,'famsizegp']='3more'\n",
    "iv, data=calc_iv(new_data,'famsizegp','target')\n",
    "ivtable.loc[ivtable['variable']=='famsize','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One-Hot\n",
    "new_data = convert_dummy(new_data,'famsizegp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptores Categóricos\n",
    "\n",
    "#### Forma de Ingresos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['inctp'].value_counts(sort=False))\n",
    "print(new_data['inctp'].value_counts(normalize=True,sort=False))\n",
    "new_data.loc[new_data['inctp']=='Pensioner','inctp']='State servant'\n",
    "new_data.loc[new_data['inctp']=='Student','inctp']='State servant'\n",
    "iv, data=calc_iv(new_data,'inctp','target')\n",
    "ivtable.loc[ivtable['variable']=='inctp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación One-Hot\n",
    "new_data = convert_dummy(new_data,'inctp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipo de Ocupación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[(new_data['occyp']=='Cleaning staff') | (new_data['occyp']=='Cooking staff') | (new_data['occyp']=='Drivers') | (new_data['occyp']=='Laborers') | (new_data['occyp']=='Low-skill Laborers') | (new_data['occyp']=='Security staff') | (new_data['occyp']=='Waiters/barmen staff'),'occyp']='Laborwk'\n",
    "new_data.loc[(new_data['occyp']=='Accountants') | (new_data['occyp']=='Core staff') | (new_data['occyp']=='HR staff') | (new_data['occyp']=='Medicine staff') | (new_data['occyp']=='Private service staff') | (new_data['occyp']=='Realty agents') | (new_data['occyp']=='Sales staff') | (new_data['occyp']=='Secretaries'),'occyp']='officewk'\n",
    "new_data.loc[(new_data['occyp']=='Managers') | (new_data['occyp']=='High skill tech staff') | (new_data['occyp']=='IT staff'),'occyp']='hightecwk'\n",
    "print(new_data['occyp'].value_counts())\n",
    "iv, data=calc_iv(new_data,'occyp','target')\n",
    "ivtable.loc[ivtable['variable']=='occyp','IV']=iv\n",
    "data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'occyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forma de Vivienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'houtp','target')\n",
    "ivtable.loc[ivtable['variable']=='houtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'houtp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Educación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['edutp']=='Academic degree','edutp']='Higher education'\n",
    "iv, data=calc_iv(new_data,'edutp','target')\n",
    "ivtable.loc[ivtable['variable']=='edutp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'edutp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Estado Civil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data['famtp'].value_counts(normalize=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'famtp','target')\n",
    "ivtable.loc[ivtable['variable']=='famtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famtp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidad de: IV y WoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede leer el artículo a continuación para comprender un poco más sobre los conceptos de IV y WoE:\n",
    "\n",
    "https://docs.tibco.com/pub/sfire-dsc/6.5.0/doc/html/TIB_sfire-dsc_user-guide/GUID-07A78308-525A-406F-8221-9281F4E9D7CF.html\n",
    "\n",
    "La tabla a continuación fue tomada de la referencia indicada:\n",
    "\n",
    "| IV| Ability to predict | \n",
    "|:------|:------:| \n",
    "| <0.02 | Bajo poder predictivo | \n",
    "|0.02~0.1 |Poder predictivo débil|\n",
    "|0.1~0.3|Poder predictivo moderado|\n",
    "|0.3~0.5|Poder predictivo fuerte|\n",
    "|>0.5|Sospechosamente alto, revisar esta variable| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=ivtable.sort_values(by='IV',ascending=False)\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','variable']='agegp'\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','variable']='worktmgp'\n",
    "ivtable.loc[ivtable['variable']=='inc','variable']='incgp'\n",
    "ivtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Buen/Mal Cliente Mediante Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomarán únicamente aquellas columnas preprocesadas y con un $IV>0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_data['target']\n",
    "X = new_data[['Gender','Reality','ChldNo_1', 'ChldNo_2More', 'gp_inc_medium',  'gp_inc_high','wkphone',\n",
    "              'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n",
    "              'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n",
    "              'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n",
    "              'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n",
    "              'houtp_Co-op apartment', 'houtp_Municipal apartment',\n",
    "              'houtp_Office apartment', 'houtp_Rented apartment',\n",
    "              'houtp_With parents','edutp_Higher education',\n",
    "              'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n",
    "              'famtp_Separated','famtp_Single / not married','famtp_Widow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "\n",
    "Concepto: Synthetic Minority Over-Sampling Technique(`SMOTE`) utilizado para lidiar con datos desbalanceados. Puede encontrar más información en:\n",
    "\n",
    "- http://glemaitre.github.io/imbalanced-learn/generated/imblearn.over_sampling.SMOTE.html\n",
    "- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int')\n",
    "sm = SMOTE()\n",
    "X_balance,Y_balance = sm.fit_resample(X,Y)\n",
    "X_balance = pd.DataFrame(X_balance, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación de datos en conjuntos: entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balance,Y_balance, \n",
    "                                                    stratify=Y_balance, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*Seleccione esta celda y luego la opción `Run All Above`\\*\n",
    "\n",
    "# PARTE 1\n",
    "\n",
    "## Separación de Conjunto de Features\n",
    "\n",
    "Teniendo en cuenta los resultados de IV obtenidos anteriormente, comprobaremos la capacidad predictiva de tres conjuntos de datos basados en la tabla anterior. Primero removeremos los últimos cuatro ('phone', 'inctp', 'email', 'Car'), y luego realizaremos la siguiente división:\n",
    "\n",
    "- A. Primera mitad: 'agegp', 'famtp', 'worktmgp', 'Reality', 'Gender', 'edutp'\n",
    "- B. Segunda mitad: 'houtp', 'famsize', 'occyp', 'incgp', 'wkphone', 'ChldNo'\n",
    "- C. Todos los descriptores.\n",
    "\n",
    "De acuerdo a estos nombres, utilice la siguiente lista para identificar aquellos solicitados en cada caso:\n",
    "```\n",
    "    'Gender','Reality','ChldNo_1', 'ChldNo_2More', 'gp_inc_medium',  'gp_inc_high','wkphone',\n",
    "    'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n",
    "    'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n",
    "    'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n",
    "    'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n",
    "    'houtp_Co-op apartment', 'houtp_Municipal apartment',\n",
    "    'houtp_Office apartment', 'houtp_Rented apartment',\n",
    "    'houtp_With parents','edutp_Higher education',\n",
    "    'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n",
    "    'famtp_Separated','famtp_Single / not married','famtp_Widow'\n",
    "```\n",
    "### A. Top 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subA = X_train[[# 'descriptor_1', 'descriptor_2', ... #]]\n",
    "\n",
    "X_test_subA = X_test[[# 'descriptor_1', 'descriptor_2', ... #]]\n",
    "\n",
    "X_train_subA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Últimos 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_subB = X_train[[# 'descriptor_1', 'descriptor_2', ... #]]\n",
    "\n",
    "X_test_subB = X_test[[# 'descriptor_1', 'descriptor_2', ... #]]\n",
    "\n",
    "X_train_subB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso C\n",
    "\n",
    "Acá simplemente tomaremos, no es necesario crear nuevas variables:\n",
    "```\n",
    "X_train_subC = X_train\n",
    "X_test_subC = X_test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 2\n",
    "\n",
    "Implementación de pruebas en los conjuntos de descriptores. A continuación debe implementar, inicialmente tres modelos de regresión logística, y posteriormente tres redes neuronales (2 capas escondidas, 20 neuronas en cada una). Observe los resultados y analice lo sucedido. Concluya sobre qué modelo es deseable teniendo en cuenta la factibilidad de implementación práctica y la matriz de confusión correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "\n",
    "Inicialmente se probará un modelo de regresión logística para tener una referencia (también se conoce como _baseline_) y comprobar que un modelo de red neuronal permite obtener mejores resultados.\n",
    "\n",
    "$$\\log ({p \\over {1 - p}}) = {\\beta _0} + {\\beta _1}{x_1} +  \\cdot  \\cdot  \\cdot  + {\\beta _q}{x_q}$$\n",
    "\n",
    "### Caso A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto A #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto A #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Regresión Logística')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto B #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto B #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Regresión Logística')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto C #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto C #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Regresión Logística')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal, Perceptrón Multicapa\n",
    "\n",
    "Ahora utilice la función `MLPClassifier` de la librería SciKit-Learn para desarrollar una red neuronal que permita mejorar el rendimiento del clasificador _baseline_ desarrollado.\n",
    "\n",
    "### Caso A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(   ) # Inicialice un modelo de red neuronal con 2 capas escondidas x 20 neuronas en cada capa y función de activación ReLu #\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto A #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto A #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Red Neuronal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(   ) # Inicialice un modelo de red neuronal con 2 capas escondidas x 20 neuronas en cada capa y función de activación ReLu #\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto B #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto B #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Red Neuronal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(   ) # Inicialice un modelo de red neuronal con 2 capas escondidas x 20 neuronas en cada capa y función de activación ReLu #\n",
    "model.fit(  ) # Ajuste el modelo con los datos del conjunto C #\n",
    "y_predict = model.predict(  ) # Realice la predicción de etiquetas con los datos de prueba del conjunto Cmm #\n",
    "\n",
    "print(f'Precisión {round(accuracy_score(y_test, y_predict),5)}')\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, \n",
    "                      title='Matriz de Confusión Normalizada: Red Neuronal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Parte 2\n",
    "\n",
    "Concluya con respecto a sus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 3\n",
    "\n",
    "Los resultados obtenidos para las redes neuronales anteriores únicamente corresponden a una arquitectura. Un proceso necesario e importante en casos de estudio como este es la búsqueda de hiperparámetros, en este caso, el número de neuronas más adecuado (al menos dentro de cierto rango, este proceso también se conoce como [GridSearch](https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e)).\n",
    "\n",
    "**Divida el conjunto de datos de prueba en dos mitades: datos de validación y datos de prueba. Utilice los datos de validación para realizar una evaluación preliminar de cada modelo.** Utilice `train_test_split` para esta parte.\n",
    "\n",
    "Utilice todos los descriptores para esta prueba y realice las siguientes búsquedas:\n",
    "\n",
    "- Caso A: 1 capa escondida $\\times$ {5, 10, 20, 50, 100} neuronas.\n",
    "- Caso B: 2 capas escondidas $\\times$ {5, 10, 20, 50, 100} neuronas.\n",
    "- Caso C: 3 capas escondidas $\\times$ {5, 10, 20, 50, 100} neuronas.\n",
    "\n",
    "Utilice `matplotlib.pyplot` para graficar la precisión en los datos de validación, seleccione el mejor modelo, y obtenga una evaluación final para esta selección utilizando los datos de prueba.\n",
    "\n",
    "### Caso A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Implemente un ciclo FOR para entrenar cada una de las configuraciones solicitadas # # # #\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Implemente un ciclo FOR para entrenar cada una de las configuraciones solicitadas # # # #\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Implemente un ciclo FOR para entrenar cada una de las configuraciones solicitadas # # # #\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficas Evaluativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bono (2 puntos)\n",
    "\n",
    "Implemente el mejor modelo de red neuronal. Desarrolle el método de **_backpropagation_** para realizar el entrenamiento de la red sin utilizar ningún tipo de librería que tenga funciones prestablecidas con objetivos de apoyo en el tema de Machine Learning. Puede utilizar Numpy, Pandas, etc. NO puede utilizar: SciKit-Learn, Tensorflow/Keras, PyTorch, etc.\n",
    "\n",
    "El bono debe estar COMPLETO y se debe observar una curva de aprendizaje a través de las iteraciones que permita obtener resultados aceptables con respecto a la red definida a partir de SciKit-Learn. De lo contrario, no se tomará como válido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Implemente el método de backpropagation para la arquitectura seleccionada # # # #\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
